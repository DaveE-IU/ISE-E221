{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "iWPCvPmiGMoj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e1c749a-925b-4553-9149-a2d641d9e5c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (5.3.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.24.0)\n",
            "Requirement already satisfied: fpdf in /usr/local/lib/python3.10/dist-packages (1.7.2)\n",
            "Requirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.10/dist-packages (from nibabel) (6.4.5)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from nibabel) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.10/dist-packages (from nibabel) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.10/dist-packages (from nibabel) (4.12.2)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.13.1)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (3.4.2)\n",
            "Requirement already satisfied: pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (11.0.0)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.36.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2024.9.20)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (0.4)\n",
            "Original shape for Patient-1: (256, 256, 23)\n",
            "Original shape for Patient-2: (320, 280, 23)\n",
            "Original shape for Patient-3: (320, 280, 20)\n",
            "Original shape for Patient-4: (256, 256, 18)\n",
            "Original shape for Patient-5: (256, 256, 26)\n",
            "Original shape for Patient-6: (256, 256, 26)\n",
            "Original shape for Patient-7: (256, 256, 22)\n",
            "Original shape for Patient-8: (256, 256, 26)\n",
            "Original shape for Patient-9: (512, 512, 30)\n",
            "Original shape for Patient-10: (320, 280, 20)\n",
            "Original shape for Patient-11: (256, 256, 18)\n",
            "Original shape for Patient-12: (256, 256, 26)\n",
            "Original shape for Patient-13: (256, 256, 18)\n",
            "Original shape for Patient-14: (320, 280, 24)\n",
            "Original shape for Patient-15: (288, 288, 25)\n",
            "Original shape for Patient-16: (512, 512, 26)\n",
            "Original shape for Patient-17: (256, 256, 18)\n",
            "Original shape for Patient-18: (256, 256, 21)\n",
            "Original shape for Patient-19: (256, 256, 26)\n",
            "Original shape for Patient-20: (256, 256, 26)\n",
            "Original shape for Patient-21: (256, 256, 26)\n",
            "Original shape for Patient-22: (256, 256, 26)\n",
            "Original shape for Patient-23: (320, 280, 28)\n",
            "Original shape for Patient-24: (256, 256, 26)\n",
            "Original shape for Patient-25: (256, 256, 26)\n",
            "Original shape for Patient-26: (320, 320, 22)\n",
            "Original shape for Patient-27: (256, 256, 26)\n",
            "Original shape for Patient-28: (320, 280, 21)\n",
            "Original shape for Patient-29: (256, 256, 18)\n",
            "Original shape for Patient-30: (256, 256, 23)\n",
            "Original shape for Patient-31: (448, 512, 27)\n",
            "Original shape for Patient-32: (256, 256, 25)\n",
            "Original shape for Patient-33: (320, 280, 20)\n",
            "Original shape for Patient-34: (512, 512, 28)\n",
            "Original shape for Patient-35: (512, 448, 20)\n",
            "Original shape for Patient-36: (256, 256, 22)\n",
            "Original shape for Patient-37: (320, 320, 30)\n",
            "Original shape for Patient-38: (256, 256, 32)\n",
            "Original shape for Patient-39: (512, 368, 21)\n",
            "Original shape for Patient-40: (512, 448, 33)\n",
            "Original shape for Patient-41: (512, 512, 28)\n",
            "Original shape for Patient-42: (448, 512, 19)\n",
            "Original shape for Patient-43: (512, 512, 18)\n",
            "Original shape for Patient-44: (256, 256, 26)\n",
            "Original shape for Patient-45: (512, 512, 24)\n",
            "Original shape for Patient-46: (256, 256, 23)\n",
            "Original shape for Patient-47: (256, 256, 26)\n",
            "Original shape for Patient-48: (256, 256, 25)\n",
            "Original shape for Patient-49: (256, 256, 26)\n",
            "Original shape for Patient-50: (256, 256, 26)\n",
            "Original shape for Patient-51: (256, 256, 26)\n",
            "Original shape for Patient-52: (512, 512, 22)\n",
            "Original shape for Patient-53: (256, 176, 19)\n",
            "Original shape for Patient-54: (320, 180, 24)\n",
            "Original shape for Patient-55: (224, 224, 29)\n",
            "Original shape for Patient-56: (512, 480, 30)\n",
            "Original shape for Patient-57: (512, 480, 27)\n",
            "Original shape for Patient-58: (512, 448, 25)\n",
            "Original shape for Patient-59: (256, 224, 22)\n",
            "Original shape for Patient-60: (288, 288, 24)\n",
            "Epoch 1/10\n",
            "2/2 [==============================] - 2s 386ms/step - loss: 1.0748 - accuracy: 0.1389 - val_loss: 0.3764 - val_accuracy: 0.9167\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 1s 182ms/step - loss: 0.4535 - accuracy: 0.8611 - val_loss: 0.5283 - val_accuracy: 0.9167\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 1s 182ms/step - loss: 0.4622 - accuracy: 0.9444 - val_loss: 0.3658 - val_accuracy: 0.9167\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 1s 184ms/step - loss: 0.2963 - accuracy: 0.8611 - val_loss: 0.3938 - val_accuracy: 0.9167\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 1s 172ms/step - loss: 0.5009 - accuracy: 0.8611 - val_loss: 0.3727 - val_accuracy: 0.9167\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 1s 180ms/step - loss: 0.3818 - accuracy: 0.8611 - val_loss: 0.3333 - val_accuracy: 0.9167\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 1s 174ms/step - loss: 0.2251 - accuracy: 0.9444 - val_loss: 0.4173 - val_accuracy: 0.8333\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 1s 178ms/step - loss: 0.2627 - accuracy: 0.9444 - val_loss: 0.4034 - val_accuracy: 0.8333\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 1s 178ms/step - loss: 0.2120 - accuracy: 0.9444 - val_loss: 0.4170 - val_accuracy: 0.9167\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 1s 180ms/step - loss: 0.2674 - accuracy: 0.9167 - val_loss: 0.4058 - val_accuracy: 0.9167\n",
            "1/1 - 0s - loss: 0.0318 - accuracy: 1.0000 - 76ms/epoch - 76ms/step\n",
            "Test accuracy: 1.0\n",
            "Processing Patient-1\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "Processing Patient-2\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Processing Patient-3\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Processing Patient-4\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Processing Patient-5\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Processing Patient-6\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "Processing Patient-7\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Processing Patient-8\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Processing Patient-9\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Processing Patient-10\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Processing Patient-11\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Processing Patient-12\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Processing Patient-13\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Processing Patient-14\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Processing Patient-15\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Processing Patient-16\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Processing Patient-17\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Processing Patient-18\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Processing Patient-19\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Processing Patient-20\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Processing Patient-21\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Processing Patient-22\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "Processing Patient-23\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Processing Patient-24\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Processing Patient-25\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Processing Patient-26\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Processing Patient-27\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Processing Patient-28\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Processing Patient-29\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Processing Patient-30\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Processing Patient-31\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Processing Patient-32\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Processing Patient-33\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Processing Patient-34\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Processing Patient-35\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Processing Patient-36\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Processing Patient-37\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Processing Patient-38\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Processing Patient-39\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Processing Patient-40\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Processing Patient-41\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Processing Patient-42\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Processing Patient-43\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Processing Patient-44\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Processing Patient-45\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Processing Patient-46\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Processing Patient-47\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Processing Patient-48\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Processing Patient-49\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Processing Patient-50\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Processing Patient-51\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Processing Patient-52\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Processing Patient-53\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Processing Patient-54\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Processing Patient-55\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Processing Patient-56\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Processing Patient-57\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Processing Patient-58\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "Processing Patient-59\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Processing Patient-60\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Report generation complete!\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install nibabel scikit-image fpdf\n",
        "\n",
        "import os\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "from scipy import ndimage as ndi\n",
        "from skimage import filters, measure, morphology, feature\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from fpdf import FPDF\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# --- Step 1: Load and Preprocess Data ---\n",
        "\n",
        "# This section defines functions to load and preprocess the MRI images.\n",
        "# It includes loading NIfTI images, smoothing, and normalizing the data.\n",
        "\n",
        "def load_patient_data(base_dir, patient_number):\n",
        "    \"\"\"Loads all NIfTI files for a given patient.\"\"\"\n",
        "    patient_dir = os.path.join(base_dir, f'Patient-{patient_number}')\n",
        "    file_names = [\n",
        "        f'{patient_number}-T1.nii',\n",
        "        f'{patient_number}-T2.nii',\n",
        "        f'{patient_number}-Flair.nii',\n",
        "        f'{patient_number}-LesionSeg-T1.nii',\n",
        "        f'{patient_number}-LesionSeg-T2.nii',\n",
        "        f'{patient_number}-LesionSeg-Flair.nii',\n",
        "    ]\n",
        "    images = {}\n",
        "    for file_name in file_names:\n",
        "        file_path = os.path.join(patient_dir, file_name)\n",
        "        try:\n",
        "            img = nib.load(file_path)\n",
        "            images[file_name.split('.')[0]] = img\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Warning: File not found: {file_path}\")\n",
        "    return images\n",
        "\n",
        "def load_and_preprocess(image_path):\n",
        "    \"\"\"Loads and preprocesses a single NIfTI image.\"\"\"\n",
        "    brain_vol = nib.load(image_path)\n",
        "    brain_vol_data = brain_vol.get_fdata()\n",
        "    smoothed_data = ndi.gaussian_filter(brain_vol_data, sigma=1)\n",
        "    normalized_data = (smoothed_data - np.min(smoothed_data)) / (np.max(smoothed_data) - np.min(smoothed_data))\n",
        "    return normalized_data, brain_vol\n",
        "\n",
        "# --- Step 2: Prepare Data for CNN ---\n",
        "\n",
        "# This section prepares the data for the CNN model.\n",
        "# It includes resizing, padding, and generating labels based on lesion segmentation.\n",
        "\n",
        "def preprocess_image(image, target_shape=(128, 128, 64)):\n",
        "    \"\"\"Preprocesses a single image for the CNN.\"\"\"\n",
        "    resized_image = tf.image.resize_with_pad(image, target_shape[0], target_shape[1]).numpy()\n",
        "    depth = resized_image.shape[2]\n",
        "    if depth < target_shape[2]:\n",
        "        pad_width = [(0, 0), (0, 0), (0, target_shape[2] - depth)]\n",
        "        resized_image = np.pad(resized_image, pad_width, mode='constant')\n",
        "    elif depth > target_shape[2]:\n",
        "        resized_image = resized_image[:, :, :target_shape[2]]\n",
        "    return resized_image\n",
        "\n",
        "def load_mri_data(base_dir, num_patients):\n",
        "    \"\"\"Loads and preprocesses MRI data for CNN training.\"\"\"\n",
        "    images = []\n",
        "    labels = []\n",
        "    for i in range(1, num_patients + 1):\n",
        "        patient_data = load_patient_data(base_dir, i)\n",
        "        if f'{i}-Flair' in patient_data:\n",
        "            flair_image_path = patient_data[f'{i}-Flair'].get_filename()\n",
        "            img, _ = load_and_preprocess(flair_image_path)\n",
        "\n",
        "            print(f\"Original shape for Patient-{i}: {img.shape}\")\n",
        "\n",
        "            img = preprocess_image(img)\n",
        "            images.append(img)\n",
        "\n",
        "            lesion_seg_path = patient_data[f'{i}-LesionSeg-Flair'].get_filename()\n",
        "            lesion_seg, _ = load_and_preprocess(lesion_seg_path)\n",
        "            threshold = 1000\n",
        "            labels.append(1 if np.sum(lesion_seg) > threshold else 0)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# --- Step 3: Split Data and Train CNN ---\n",
        "\n",
        "# This section defines the CNN model architecture,\n",
        "# splits the data into training and testing sets, and trains the model.\n",
        "\n",
        "def create_cnn_model(input_shape=(128, 128, 64)):\n",
        "    \"\"\"Creates a CNN model for flare-up detection.\"\"\"\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Input(shape=input_shape),\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# --- Step 4: Lesion Segmentation ---\n",
        "\n",
        "# This section defines a function to segment the lesions in the MRI images.\n",
        "# It uses thresholding and morphological operations to identify and isolate lesions.\n",
        "\n",
        "def segment_lesions(normalized_data):\n",
        "    \"\"\"Segments lesions in the image.\"\"\"\n",
        "    threshold_value = filters.threshold_otsu(normalized_data)\n",
        "    binary_lesions = normalized_data > threshold_value\n",
        "    cleaned_lesions = morphology.remove_small_objects(binary_lesions, min_size=500)\n",
        "    labeled_lesions, num_lesions = measure.label(cleaned_lesions, return_num=True)\n",
        "    properties = measure.regionprops(labeled_lesions, intensity_image=normalized_data)\n",
        "    return labeled_lesions, properties\n",
        "\n",
        "# --- Step 5: Feature Extraction and Analysis ---\n",
        "\n",
        "# This section defines a function to extract various features from the images.\n",
        "# It includes calculating mean intensity, lesion properties, and texture features.\n",
        "\n",
        "def extract_features(normalized_data, labeled_lesions, properties, brain_vol):\n",
        "    \"\"\"Extracts features and performs analysis.\"\"\"\n",
        "    features = {\n",
        "        'mean_intensity': np.mean(normalized_data),\n",
        "        'max_intensity': np.max(normalized_data),\n",
        "        'min_intensity': np.min(normalized_data),\n",
        "        'std_dev': np.std(normalized_data)\n",
        "    }\n",
        "\n",
        "    lesion_areas = [prop.area for prop in properties]\n",
        "    mean_intensities = [prop.mean_intensity for prop in properties]\n",
        "    lesion_volumes = [prop.area * np.prod(brain_vol.header.get_zooms()) for prop in properties]\n",
        "    total_lesion_volume = sum(lesion_volumes)\n",
        "\n",
        "    slice_index = normalized_data.shape[2] // 2\n",
        "    glcm = feature.graycomatrix((normalized_data[:, :, slice_index] * 255).astype('uint8'),\n",
        "                                 distances=[1], angles=[0], symmetric=True, normed=True)\n",
        "    contrast = feature.graycoprops(glcm, 'contrast')[0, 0]\n",
        "    dissimilarity = feature.graycoprops(glcm, 'dissimilarity')[0, 0]\n",
        "    homogeneity = feature.graycoprops(glcm, 'homogeneity')[0, 0]\n",
        "    energy = feature.graycoprops(glcm, 'energy')[0, 0]\n",
        "    correlation = feature.graycoprops(glcm, 'correlation')[0, 0]\n",
        "\n",
        "    texture_features = {\n",
        "        'contrast': contrast,\n",
        "        'dissimilarity': dissimilarity,\n",
        "        'homogeneity': homogeneity,\n",
        "        'energy': energy,\n",
        "        'correlation': correlation\n",
        "    }\n",
        "\n",
        "    return features, lesion_areas, mean_intensities, total_lesion_volume, texture_features\n",
        "\n",
        "# --- Step 6: Visualization ---\n",
        "\n",
        "# This section defines a function to generate visualizations of the data.\n",
        "# It includes plotting the original image, lesion overlay, and lesion properties.\n",
        "\n",
        "def generate_visualizations(normalized_data, labeled_lesions, lesion_areas, mean_intensities, output_dir, patient_number):\n",
        "    \"\"\"Generates and saves visualizations.\"\"\"\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    slice_index = min(10 + patient_number % 10, normalized_data.shape[2] - 1)\n",
        "    #slice_index = 10 + patient_number % 10\n",
        "\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
        "    ax[0].imshow(normalized_data[:, :, slice_index], cmap='gray')\n",
        "    ax[0].set_title('Original Image')\n",
        "    ax[0].axis('off')\n",
        "    ax[1].imshow(normalized_data[:, :, slice_index], cmap='gray')\n",
        "    ax[1].contour(labeled_lesions[:, :, slice_index], colors='r')\n",
        "    ax[1].set_title('Lesions Overlay')\n",
        "    ax[1].axis('off')\n",
        "    plt.tight_layout()\n",
        "    lesion_overlay_path = os.path.join(output_dir, f'lesion_overlay_{patient_number}.png')\n",
        "    plt.savefig(lesion_overlay_path)\n",
        "    plt.close(fig)\n",
        "\n",
        "    plt.hist(lesion_areas, bins=20, color='blue', alpha=0.7)\n",
        "    plt.title('Lesion Size Distribution')\n",
        "    plt.xlabel('Area')\n",
        "    plt.ylabel('Frequency')\n",
        "    lesion_size_distribution_path = os.path.join(output_dir, f'lesion_size_distribution_{patient_number}.png')\n",
        "    plt.savefig(lesion_size_distribution_path)\n",
        "    plt.close()\n",
        "\n",
        "    plt.hist(mean_intensities, bins=20, color='green', alpha=0.7)\n",
        "    plt.title('Intensity Distribution in Lesions')\n",
        "    plt.xlabel('Mean Intensity')\n",
        "    plt.ylabel('Frequency')\n",
        "    intensity_distribution_path = os.path.join(output_dir, f'intensity_distribution_{patient_number}.png')\n",
        "    plt.savefig(intensity_distribution_path)\n",
        "    plt.close()\n",
        "\n",
        "    plt.hist(normalized_data.flatten(), bins=50, color='purple', alpha=0.7)\n",
        "    plt.title('Overall Intensity Distribution')\n",
        "    plt.xlabel('Intensity')\n",
        "    plt.ylabel('Frequency')\n",
        "    overall_intensity_path = os.path.join(output_dir, f'overall_intensity_distribution_{patient_number}.png')\n",
        "    plt.savefig(overall_intensity_path)\n",
        "    plt.close()\n",
        "\n",
        "    return (\n",
        "        lesion_overlay_path,\n",
        "        lesion_size_distribution_path,\n",
        "        intensity_distribution_path,\n",
        "        overall_intensity_path,\n",
        "    )\n",
        "\n",
        "# --- Step 7: Report Generation ---\n",
        "\n",
        "# This section defines a function to generate a PDF report summarizing the analysis.\n",
        "# It includes information about the detected flare-ups, features, and visualizations.\n",
        "\n",
        "class PDF(FPDF):\n",
        "    def header(self):\n",
        "        self.set_font('Arial', 'B', 12)\n",
        "        self.cell(0, 10, 'Medical Image Classification Report', 0, 1, 'C')\n",
        "        self.ln(10)\n",
        "\n",
        "    def chapter_title(self, title):\n",
        "        self.set_font('Arial', 'B', 12)\n",
        "        self.cell(0, 10, title, 0, 1, 'L')\n",
        "        self.ln(5)\n",
        "\n",
        "    def chapter_body(self, body):\n",
        "        self.set_font('Arial', '', 12)\n",
        "        self.multi_cell(0, 10, body)\n",
        "        self.ln()\n",
        "\n",
        "def generate_report(pdf, features, flare_up_detected, lesion_areas,\n",
        "                    mean_intensities, total_lesion_volume, texture_features,\n",
        "                    output_dir, visualizations, patient_number):\n",
        "    \"\"\"Generates a PDF report for a single patient.\"\"\"\n",
        "\n",
        "    pdf.add_page()\n",
        "    pdf.chapter_title(f'Patient-{patient_number} Analysis')\n",
        "\n",
        "    pdf.chapter_body(f\"Flare-up detected (CNN): {flare_up_detected}\")\n",
        "\n",
        "    pdf.chapter_title('Features')\n",
        "    results_body = \"\\n\".join([f\"{key}: {value}\" for key, value in features.items()])\n",
        "    pdf.chapter_body(results_body)\n",
        "\n",
        "    pdf.chapter_title('Lesion Properties')\n",
        "    pdf.chapter_body(f\"Number of Lesions: {len(lesion_areas)}\")\n",
        "    pdf.chapter_body(f\"Total Lesion Volume: {total_lesion_volume:.2f} mm3\")\n",
        "\n",
        "    pdf.chapter_title('Texture Features')\n",
        "    texture_labels = list(texture_features.keys())\n",
        "    texture_values = list(texture_features.values())\n",
        "\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.bar(texture_labels, texture_values, color='skyblue')\n",
        "    plt.title(f'Patient-{patient_number} Texture Features')\n",
        "    plt.ylabel('Value')\n",
        "    texture_chart_path = os.path.join(output_dir, f'texture_features_{patient_number}.png')\n",
        "    plt.savefig(texture_chart_path)\n",
        "    plt.close()\n",
        "\n",
        "    pdf.image(texture_chart_path, x=10, y=None, w=150)\n",
        "\n",
        "    pdf.chapter_title('Visualizations')\n",
        "    pdf.image(visualizations[0], x=10, y=None, w=150)\n",
        "    pdf.image(visualizations[1], x=10, y=None, w=150)\n",
        "    pdf.image(visualizations[2], x=10, y=None, w=150)\n",
        "    pdf.image(visualizations[3], x=10, y=None, w=150)\n",
        "\n",
        "# --- Main Execution ---\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    base_directory = '/content/drive/MyDrive/Colab Notebooks/MRI'\n",
        "    output_dir = '/content/drive/MyDrive/Colab Notebooks/Reports'\n",
        "    num_patients = 60\n",
        "\n",
        "    mri_images, labels = load_mri_data(base_directory, num_patients)\n",
        "\n",
        "    train_images, temp_images, train_labels, temp_labels = train_test_split(\n",
        "        mri_images, labels, test_size=0.4, random_state=42\n",
        "    )\n",
        "    val_images, test_images, val_labels, test_labels = train_test_split(\n",
        "        temp_images, temp_labels, test_size=0.5, random_state=42\n",
        "    )\n",
        "\n",
        "    input_shape = (128, 128, 64)\n",
        "    model = create_cnn_model(input_shape)\n",
        "    history = model.fit(\n",
        "        train_images, train_labels, epochs=10, validation_data=(val_images, val_labels)\n",
        "    )\n",
        "\n",
        "    test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
        "    print(f\"Test accuracy: {test_acc}\")\n",
        "\n",
        "    pdf = PDF()\n",
        "    for i in range(1, num_patients + 1):\n",
        "        print(f\"Processing Patient-{i}\")\n",
        "        patient_data = load_patient_data(base_directory, i)\n",
        "        if f'{i}-Flair' in patient_data:\n",
        "            normalized_data, brain_vol = load_and_preprocess(patient_data[f'{i}-Flair'].get_filename())\n",
        "            labeled_lesions, properties = segment_lesions(normalized_data)\n",
        "            features, lesion_areas, mean_intensities, total_lesion_volume, texture_features = extract_features(\n",
        "                normalized_data, labeled_lesions, properties, brain_vol\n",
        "            )\n",
        "\n",
        "            input_image = preprocess_image(normalized_data)\n",
        "            flare_up_detected = model.predict(np.expand_dims(input_image, axis=0)) > 0.5\n",
        "\n",
        "            visualizations = generate_visualizations(\n",
        "                normalized_data, labeled_lesions, lesion_areas, mean_intensities, output_dir, i\n",
        "            )\n",
        "\n",
        "            generate_report(\n",
        "                pdf, features, flare_up_detected, lesion_areas, mean_intensities,\n",
        "                total_lesion_volume, texture_features, output_dir, visualizations, i\n",
        "            )\n",
        "\n",
        "    pdf.output(os.path.join(output_dir, 'Medical_Image_Classification_Report.pdf'))\n",
        "    print(\"Report generation complete!\")"
      ]
    }
  ]
}